import math
import numpy as np
import pandas as pd
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional
from sqlalchemy.future import select
from sqlalchemy.ext.asyncio import AsyncSession

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —á–∞—Å—Ç–∏, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å circular imports
try:
    from database import ProductCost
except ImportError:
    pass

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–µ–Ω–∏–≤—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞ clickhouse, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ —Ü–∏–∫–ª–æ–≤
try:
    from services.clickhouse_models import ch_service
except ImportError:
    # Fallback –µ—Å–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫ –¥—Ä—É–≥–∞—è (–≤–Ω—É—Ç—Ä–∏ docker)
    try:
        from clickhouse_models import ch_service
    except:
        ch_service = None

logger = logging.getLogger("Analysis-Economics")

class EconomicsModule:
    
    def calculate_supply_metrics(
        self, 
        current_stock: int, 
        sales_history: List[Dict[str, Any]], 
        forecast_data: Optional[Dict[str, Any]] = None,
        lead_time_days: int = 7,  # –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–æ—Å—Ç–∞–≤–∫–∏
        lead_time_sigma: int = 2, # –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—Å—Ç–∞–≤–∫–∏ (–¥–Ω–µ–π)
        service_level_z: float = 1.65 # Z-score –¥–ª—è 95% —É—Ä–æ–≤–Ω—è —Å–µ—Ä–≤–∏—Å–∞
    ) -> Dict[str, Any]:
        """
        –†–∞—Å—á–µ—Ç —Ç–æ—á–∫–∏ –∑–∞–∫–∞–∑–∞ (ROP) –∏ —Å—Ç—Ä–∞—Ö–æ–≤–æ–≥–æ –∑–∞–ø–∞—Å–∞ (Safety Stock).
        """
        # 1. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ø—Ä–æ—Å (Demand)
        if forecast_data and forecast_data.get("status") == "success":
            avg_daily_demand = forecast_data.get("daily_avg_forecast", 0)
            forecast_points = forecast_data.get("forecast_points", [])
            demand_during_lead_time = sum([p['yhat'] for p in forecast_points[:lead_time_days]])
        else:
            if not sales_history:
                return {"status": "error", "message": "No data"}
            values = [x['qty'] for x in sales_history if x['qty'] > 0]
            if not values:
                return {"status": "error", "message": "Zero sales"}
            avg_daily_demand = np.mean(values)
            demand_during_lead_time = avg_daily_demand * lead_time_days

        # 2. –°—á–∏—Ç–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ —Å–ø—Ä–æ—Å–∞ (sigma_Demand)
        if sales_history:
            hist_values = [x['qty'] for x in sales_history]
            sigma_demand = np.std(hist_values) if len(hist_values) > 1 else 0
        else:
            sigma_demand = 0

        # 3. –†–∞—Å—á–µ—Ç Safety Stock
        term1 = lead_time_days * (sigma_demand ** 2)
        term2 = (avg_daily_demand ** 2) * (lead_time_sigma ** 2)
        safety_stock = service_level_z * math.sqrt(term1 + term2)
        
        # 4. –†–∞—Å—á–µ—Ç ROP
        rop = demand_during_lead_time + safety_stock
        
        # 5. –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
        days_left = current_stock / avg_daily_demand if avg_daily_demand > 0 else 999
        
        safety_stock = int(math.ceil(safety_stock))
        rop = int(math.ceil(rop))
        days_left = int(days_left)
        
        status = "ok"
        recommendation = "–ó–∞–ø–∞—Å–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ"
        
        if current_stock <= 0:
            status = "out_of_stock"
            recommendation = "–¢–æ–≤–∞—Ä–∞ –Ω–µ—Ç –≤ –Ω–∞–ª–∏—á–∏–∏!"
        elif current_stock < safety_stock:
            status = "critical"
            recommendation = "–°—Ä–æ—á–Ω–æ –ø–æ–ø–æ–ª–Ω–∏—Ç—å! (–ù–∏–∂–µ —Å—Ç—Ä–∞—Ö–æ–≤–æ–≥–æ –∑–∞–ø–∞—Å–∞)"
        elif current_stock < rop:
            status = "warning"
            recommendation = f"–ü–æ—Ä–∞ –∑–∞–∫–∞–∑—ã–≤–∞—Ç—å (–ù–∏–∂–µ —Ç–æ—á–∫–∏ –∑–∞–∫–∞–∑–∞ {rop} —à—Ç)"
            
        return {
            "status": status,
            "recommendation": recommendation,
            "metrics": {
                "safety_stock": safety_stock,
                "rop": rop,
                "days_left": days_left,
                "avg_daily_demand": round(avg_daily_demand, 1),
                "demand_lead_time": round(demand_during_lead_time, 1),
                "current_stock": current_stock
            },
            "inputs": {
                "lead_time": lead_time_days,
                "service_level": "95%"
            }
        }

    async def get_pnl_data(self, user_id: int, date_from: datetime, date_to: datetime, db: AsyncSession) -> List[Dict[str, Any]]:
        """
        –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç P&L. –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ ClickHouse.
        –î–û–ë–ê–í–õ–ï–ù –†–ê–°–ß–ï–¢ –ù–ê–õ–û–ì–ê 6%.
        """
        logger.info(f"üìä [PnL] –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –¥–ª—è user={user_id}")

        if not ch_service:
            logger.error("ClickHouse service module not imported")
            return []

        ch_client = ch_service.get_client()
        if not ch_client:
            logger.warning("‚ö†Ô∏è ClickHouse client not available")
            return []

        # 1. –ê–≥—Ä–µ–≥–∞—Ü–∏—è –≤ ClickHouse (SQL Optimization)
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –î–∞—Ç–µ –∏ SKU —Å—Ä–∞–∑—É, —á—Ç–æ–±—ã –Ω–µ —Ç—è–Ω—É—Ç—å –º–∏–ª–ª–∏–æ–Ω—ã —Å—Ç—Ä–æ–∫.
        # –°—á–∏—Ç–∞–µ–º —Å—É–º–º—ã –ø—Ä–æ–¥–∞–∂, –≤–æ–∑–≤—Ä–∞—Ç–æ–≤, –ª–æ–≥–∏—Å—Ç–∏–∫–∏ –∏ –∫–æ–º–∏—Å—Å–∏–π.
        ch_query = """
        SELECT 
            toDate(sale_dt) as report_date,
            nm_id,
            sumIf(retail_price_withdisc_rub, doc_type_name = '–ü—Ä–æ–¥–∞–∂–∞') - sumIf(retail_price_withdisc_rub, doc_type_name = '–í–æ–∑–≤—Ä–∞—Ç') as gross_sales,
            sum(ppvz_for_pay) as net_sales,
            sum(ppvz_sales_commission) as wb_commission,
            sum(delivery_rub) as logistics,
            sum(penalty) as penalties,
            sum(additional_payment) as adjustments,
            sumIf(quantity, doc_type_name = '–ü—Ä–æ–¥–∞–∂–∞') as qty_sold,
            sumIf(quantity, doc_type_name = '–í–æ–∑–≤—Ä–∞—Ç') as qty_returned
        FROM wb_analytics.realization_reports FINAL
        WHERE supplier_id = {uid:UInt64} 
          AND sale_dt >= {start:DateTime} 
          AND sale_dt <= {end:DateTime}
        GROUP BY report_date, nm_id
        ORDER BY report_date ASC
        """
        
        params = {
            'uid': user_id, 
            'start': date_from, 
            'end': date_to
        }
        
        try:
            result = ch_client.query(ch_query, parameters=params)
            rows = result.result_rows
        except Exception as e:
            logger.error(f"‚ùå ClickHouse Query Error: {e}")
            return []

        if not rows: 
            return []

        # 2. –ü–æ–ª—É—á–∞–µ–º —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å –∏–∑ Postgres
        # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ SKU –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        unique_skus = list(set([row[1] for row in rows]))
        
        costs_map = {}
        try:
            from database import ProductCost
            stmt = select(ProductCost).where(ProductCost.user_id == user_id, ProductCost.sku.in_(unique_skus))
            cogs_result = await db.execute(stmt)
            costs_map = {c.sku: c.cost_price for c in cogs_result.scalars().all()}
        except Exception as e:
            logger.error(f"Error fetching product costs: {e}")

        # 3. –§–∏–Ω–∞–ª—å–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –¥–Ω—è–º –≤ Python
        daily_pnl = {}
        
        for row in rows:
            r_date, sku, gross, net_pay, commission, logistics, penalties, adjustments, q_sold, q_ret = row
            
            # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤
            gross = float(gross or 0)
            net_pay = float(net_pay or 0)
            commission = float(commission or 0)
            logistics = float(logistics or 0)
            penalties = float(penalties or 0)
            adjustments = float(adjustments or 0)
            q_sold = int(q_sold or 0)
            q_ret = int(q_ret or 0)

            # –†–∞—Å—á–µ—Ç —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–¥–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ (COGS)
            unit_cost = costs_map.get(sku, 0)
            total_cogs = (q_sold - q_ret) * unit_cost
            
            # --- FIX: –†–ê–°–ß–ï–¢ –ù–ê–õ–û–ì–ê (6% –æ—Ç –í–´–†–£–ß–ö–ò) ---
            # –ù–∞–ª–æ–≥ –ø–ª–∞—Ç–∏—Ç—Å—è —Å "–í—ã—Ä—É—á–∫–∏" (Gross Sales), –∞ –Ω–µ —Å —Ç–æ–≥–æ, —á—Ç–æ –ø—Ä–∏—à–ª–æ –Ω–∞ —Å—á–µ—Ç!
            tax = (gross * 0.06) if gross > 0 else 0

            date_str = r_date.strftime("%Y-%m-%d")
            
            if date_str not in daily_pnl:
                daily_pnl[date_str] = {
                    "date": date_str, 
                    "gross_sales": 0.0,
                    "net_sales": 0.0,
                    "cogs": 0.0,
                    "commission": 0.0,
                    "logistics": 0.0,
                    "penalties": 0.0,
                    "adjustments": 0.0,
                    "tax": 0.0, # –ù–æ–≤—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä
                    "cm3": 0.0 
                }
            
            d = daily_pnl[date_str]
            d["gross_sales"] += gross
            d["net_sales"] += net_pay
            d["commission"] += commission
            d["logistics"] += logistics
            d["penalties"] += penalties
            d["adjustments"] += adjustments
            d["cogs"] += total_cogs
            d["tax"] += tax
        
        # 4. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Å–ø–∏—Å–∫–∞
        final_output = []
        for date_str, m in sorted(daily_pnl.items()):
            # –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å (Net Profit)
            # = (–ö –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—é + –î–æ–ø–ª–∞—Ç—ã) - –õ–æ–≥–∏—Å—Ç–∏–∫–∞ - –®—Ç—Ä–∞—Ñ—ã - –°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å - –ù–∞–ª–æ–≥
            m["cm3"] = (m["net_sales"] + m["adjustments"]) - m["logistics"] - m["penalties"] - m["cogs"] - m["tax"]
            
            # –û–∫—Ä—É–≥–ª—è–µ–º –¥–ª—è –∫—Ä–∞—Å–æ—Ç—ã
            for k in ["gross_sales", "net_sales", "cogs", "commission", "logistics", "penalties", "adjustments", "tax", "cm3"]:
                m[k] = round(m[k], 2)
            
            final_output.append(m)
            
        return final_output

    def calculate_metrics(self, raw_data: dict):
        if raw_data.get("status") == "error": return raw_data
        p = raw_data.get("prices", {})
        wallet = p.get("wallet_purple", 0)
        standard = p.get("standard_black", 0)
        base = p.get("base_crossed", 0)
        benefit = standard - wallet if standard > wallet else 0
        discount_pct = round(((base - wallet) / base * 100), 1) if base > 0 else 0
        raw_data["metrics"] = {
            "wallet_benefit": benefit,
            "total_discount_percent": discount_pct,
            "is_favorable": discount_pct > 45
        }
        return raw_data

    def calculate_transit_benefit(self, volume_liters: int):
        koledino_direct_cost = volume_liters * 30 * 1 
        kazan_transit_cost = 1500 + (volume_liters * 20 * 0) 
        benefit = koledino_direct_cost - kazan_transit_cost
        return {
            "direct_cost": koledino_direct_cost,
            "transit_cost": kazan_transit_cost,
            "benefit": benefit,
            "is_profitable": benefit > 0,
            "recommendation": "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç—Ä–∞–Ω–∑–∏—Ç —á–µ—Ä–µ–∑ –ö–∞–∑–∞–Ω—å" if benefit > 0 else "–ü—Ä—è–º–∞—è –ø–æ—Å—Ç–∞–≤–∫–∞ –≤—ã–≥–æ–¥–Ω–µ–µ"
        }
    
    def calculate_real_logistics(self, volume_l: float, warehouse_tariffs: dict) -> float:
        """
        –°—á–∏—Ç–∞–µ—Ç –ª–æ–≥–∏—Å—Ç–∏–∫—É –ø–æ —Ñ–æ—Ä–º—É–ª–µ WB:
        –ë–∞–∑–∞ (–∑–∞ 5–ª) + (–û–±—ä–µ–º - 5) * –°—Ç–∞–≤–∫–∞ –∑–∞ –ª–∏—Ç—Ä
        """
        target_wh = warehouse_tariffs.get('–ö–æ–ª–µ–¥–∏–Ω–æ') or warehouse_tariffs.get('–ü–æ–¥–æ–ª—å—Å–∫')
        
        if not target_wh:
            return 50.0 # Fallback
            
        base_price = target_wh['base'] 
        liter_price = target_wh['liter'] 
        
        if volume_l <= 5:
            return base_price
        
        extra_liters = volume_l - 5
        cost = base_price + (extra_liters * liter_price)
        return round(cost, 2)

    def calculate_abc_xyz(self, sales_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        –†–∞—Å—á–µ—Ç ABC/XYZ –∞–Ω–∞–ª–∏–∑–∞.
        """
        if not sales_data:
            return {"status": "error", "message": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"}

        try:
            df = pd.DataFrame(sales_data)
            df['revenue'] = pd.to_numeric(df['revenue'], errors='coerce').fillna(0)
            df['qty'] = pd.to_numeric(df['qty'], errors='coerce').fillna(0)
            
            # ABC
            abc_df = df.groupby('sku')['revenue'].sum().reset_index()
            abc_df = abc_df.sort_values(by='revenue', ascending=False)
            total_revenue = abc_df['revenue'].sum()
            
            if total_revenue == 0:
                return {"status": "error", "message": "–û–±—â–∞—è –≤—ã—Ä—É—á–∫–∞ —Ä–∞–≤–Ω–∞ 0"}

            abc_df['cumsum'] = abc_df['revenue'].cumsum()
            abc_df['share'] = abc_df['cumsum'] / total_revenue
            
            def get_abc(share):
                if share <= 0.8: return 'A'
                elif share <= 0.95: return 'B'
                return 'C'
            abc_df['abc_class'] = abc_df['share'].apply(get_abc)
            abc_map = abc_df.set_index('sku')['abc_class'].to_dict()

            # XYZ
            daily_sales = df.groupby(['sku', 'date'])['qty'].sum().reset_index()
            xyz_stats = daily_sales.groupby('sku')['qty'].agg(['std', 'mean']).reset_index()
            xyz_stats['cv'] = np.where(xyz_stats['mean'] > 0, xyz_stats['std'] / xyz_stats['mean'], 0)
            xyz_stats['cv'] = xyz_stats['cv'].fillna(0)

            def get_xyz(cv):
                if cv <= 0.1: return 'X'
                elif cv <= 0.25: return 'Y'
                return 'Z'
            xyz_stats['xyz_class'] = xyz_stats['cv'].apply(get_xyz)
            xyz_map = xyz_stats.set_index('sku')['xyz_class'].to_dict()

            results = {}
            all_skus = set(abc_map.keys()) | set(xyz_map.keys())
            summary_counts = {g: 0 for g in ["AX","AY","AZ","BX","BY","BZ","CX","CY","CZ"]}

            for sku in all_skus:
                a = abc_map.get(sku, 'C')
                x = xyz_map.get(sku, 'Z')
                group = f"{a}{x}"
                results[sku] = {"abc": a, "xyz": x, "group": group}
                if group in summary_counts: summary_counts[group] += 1
                    
            return {"status": "success", "items": results, "summary": summary_counts}

        except Exception as e:
            return {"status": "error", "message": str(e)}
    
    async def get_return_forensics(self, user_id: int, date_from: datetime, date_to: datetime) -> Dict[str, Any]:
        """
        –§–æ—Ä–µ–Ω–∑–∏–∫–∞ –í–æ–∑–≤—Ä–∞—Ç–æ–≤.
        """
        ch_query_sizes = """
        SELECT 
            nm_id,
            ts_name as size,
            sumIf(quantity, doc_type_name = '–ü—Ä–æ–¥–∞–∂–∞') as sales,
            sumIf(quantity, doc_type_name = '–í–æ–∑–≤—Ä–∞—Ç') as returns,
            sumIf(delivery_rub, doc_type_name = '–í–æ–∑–≤—Ä–∞—Ç') as return_logistics_cost,
            sumIf(retail_price_withdisc_rub, doc_type_name = '–ü—Ä–æ–¥–∞–∂–∞') as revenue
        FROM wb_analytics.realization_reports FINAL
        WHERE supplier_id = {uid:UInt64} 
          AND sale_dt >= {start:DateTime} 
          AND sale_dt <= {end:DateTime}
        GROUP BY nm_id, size
        HAVING (sales + returns) > 5
        ORDER BY returns DESC
        """

        ch_query_warehouses = """
        SELECT 
            nm_id,
            office_name as warehouse,
            sumIf(quantity, doc_type_name = '–ü—Ä–æ–¥–∞–∂–∞') as sales,
            sumIf(quantity, doc_type_name = '–í–æ–∑–≤—Ä–∞—Ç') as returns,
            sumIf(delivery_rub, doc_type_name = '–í–æ–∑–≤—Ä–∞—Ç') as return_logistics_cost
        FROM wb_analytics.realization_reports FINAL
        WHERE supplier_id = {uid:UInt64} 
          AND sale_dt >= {start:DateTime} 
          AND sale_dt <= {end:DateTime}
        GROUP BY nm_id, warehouse
        HAVING returns > 0
        ORDER BY returns DESC
        """
        
        params = {'uid': user_id, 'start': date_from, 'end': date_to}
        
        try:
            ch_client = ch_service.get_client()
            if not ch_client:
                return {"status": "error", "message": "ClickHouse connection unavailable"}
            rows_sizes = ch_client.query(ch_query_sizes, parameters=params).result_rows
            rows_wh = ch_client.query(ch_query_warehouses, parameters=params).result_rows
        except Exception as e:
            logger.error(f"Forensics Query Error: {e}")
            return {"status": "error", "message": str(e)}

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ Sizes
        size_anomalies = []
        for r in rows_sizes:
            nm_id, size, sales, returns, ret_cost, rev = r
            sales = int(sales) if sales else 0
            returns = int(returns) if returns else 0
            total_ops = sales + returns
            buyout_rate = round((sales / total_ops) * 100, 1) if total_ops > 0 else 0
            
            if buyout_rate < 30 and total_ops > 10: verdict = "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–∏–π –≤—ã–∫—É–ø. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–µ–∫–∞–ª–∞."
            elif buyout_rate < 50: verdict = "–ù–∏–∑–∫–∏–π –≤—ã–∫—É–ø. –í–æ–∑–º–æ–∂–Ω–æ, –±–æ–ª—å—à–µ–º–µ—Ä/–º–∞–ª–æ–º–µ—Ä."
            else: verdict = "–ù–æ—Ä–º–∞"

            size_anomalies.append({
                "nm_id": nm_id, "size": size, "buyout_rate": buyout_rate,
                "sales": sales, "returns": returns,
                "loss_on_returns": round(float(ret_cost), 2) if ret_cost else 0.0,
                "verdict": verdict
            })

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ Warehouses
        wh_stats = []
        for r in rows_wh:
            nm_id, wh, sales, returns, ret_cost = r
            sales = int(sales) if sales else 0
            returns = int(returns) if returns else 0
            total_ops = sales + returns
            return_rate = round((returns / total_ops) * 100, 1) if total_ops > 0 else 0
            
            wh_stats.append({
                "nm_id": nm_id, "warehouse": wh, "return_rate": return_rate,
                "returns_count": returns, "cost": round(float(ret_cost), 2) if ret_cost else 0.0
            })

        return {
            "size_analysis": sorted(size_anomalies, key=lambda x: x['buyout_rate']),
            "warehouse_analysis": sorted(wh_stats, key=lambda x: x['return_rate'], reverse=True)[:20]
        }