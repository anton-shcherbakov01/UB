import asyncio
import logging
import random
import json
from urllib.parse import quote
from typing import Dict, Any

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–∞–≥–∏—é, –∫–æ—Ç–æ—Ä–∞—è –ª–µ—á–∏—Ç TLS Fingerprint
from curl_cffi.requests import AsyncSession

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("WBSearch")

GEO_ZONES = {
    "moscow": "-1257786",      
    "spb": "-1257786",         
    "kazan": "-2133464",       
    "krasnodar": "-1192533",   
    "ekb": "-1113276",         
    "novosibirsk": "-1282245", 
    "khabarovsk": "-1216606",
    "belarus": "1235",         
    "kazakhstan": "-1227092"
}

class WBSearchService:
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º API –∫–∞—Ç–∞–ª–æ–≥–∞, –æ–Ω–æ —Ä–µ–∂–µ –±–∞–Ω–∏—Ç, —á–µ–º search.wb.ru
    # –ù–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ V9 —Ç–æ–∂–µ –ø–æ–¥–æ–π–¥–µ—Ç, –µ—Å–ª–∏ –ø—Ä–∏—Ç–≤–æ—Ä–∏—Ç—å—Å—è —Ö—Ä–æ–º–æ–º
    BASE_URL = "https://search.wb.ru/exactmatch/ru/common/v9/search"

    async def get_sku_position(self, query: str, target_sku: int, geo: str = "moscow", depth_pages: int = 5) -> Dict[str, Any]:
        dest_id = GEO_ZONES.get(geo, GEO_ZONES["moscow"])
        encoded_query = quote(query)
        target_sku = int(target_sku)
        
        logger.info(f"üõ°Ô∏è [TLS-Bypass] –ò—â—É SKU {target_sku} –ø–æ '{query}' (Geo: {geo})")

        result = {
            "sku": target_sku,
            "query": query,
            "geo": geo,
            "found": False,
            "page": None,
            "position": None,
            "absolute_pos": None,
            "is_advertising": False,
            "cpm": None,
            "total_products": 0,
            "debug_logs": []
        }

        # impersonate="chrome120" ‚Äî –ö–ª—é—á–µ–≤–æ–π –º–æ–º–µ–Ω—Ç!
        # –ú—ã –≥–æ–≤–æ—Ä–∏–º —Å–µ—Ä–≤–µ—Ä—É: "–Ø —Ä–µ–∞–ª—å–Ω—ã–π Chrome 120", –∏ –ø–æ–¥–¥–µ–ª—ã–≤–∞–µ–º TLS-—Ö–µ–Ω–¥—à–µ–π–∫.
        async with AsyncSession(impersonate="chrome120") as session:
            tasks = []
            for page in range(1, depth_pages + 1):
                # appType=1 (Desktop), —Ç–∞–∫ –∫–∞–∫ –º—ã –ø—Ä–∏—Ç–≤–æ—Ä—è–µ–º—Å—è –¥–µ—Å–∫—Ç–æ–ø–Ω—ã–º —Ö—Ä–æ–º–æ–º
                url = (
                    f"{self.BASE_URL}?"
                    f"ab_testing=false&appType=1&curr=rub&dest={dest_id}"
                    f"&query={encoded_query}&resultset=catalog&sort=popular"
                    f"&spp=30&suppressSpellcheck=false&page={page}"
                )
                tasks.append(self._fetch_page(session, url, page))
            
            pages_data = await asyncio.gather(*tasks)

        global_counter = 0
        sorted_pages = sorted(pages_data, key=lambda x: x['page'])
        
        for p_data in sorted_pages:
            status_line = f"Page {p_data['page']}: {len(p_data['products'])} items. (HTTP {p_data['status']})"
            logger.info(status_line)
            result['debug_logs'].append(status_line)

            if p_data['page'] == 1:
                result['total_products'] = p_data['total']

            for idx, prod in enumerate(p_data['products']):
                global_counter += 1
                if prod.get('id') == target_sku:
                    logger.info(f"üéØ FOUND! Abs Pos: {global_counter}")
                    result['found'] = True
                    result['page'] = p_data['page']
                    result['position'] = idx + 1
                    result['absolute_pos'] = global_counter
                    if prod.get('log'):
                        result['is_advertising'] = True
                        result['cpm'] = prod.get('log', {}).get('cpm')
                    return result

        return result

    async def _fetch_page(self, session, url, page_num):
        try:
            # curl_cffi –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ User-Agent –≤—Ä—É—á–Ω—É—é, –æ–Ω —Å—Ç–∞–≤–∏—Ç –∏—Ö —Å–∞–º –∏–∑ –ø—Ä–µ—Å–µ—Ç–∞
            resp = await session.get(url, timeout=10)
            
            if resp.status_code == 200:
                try:
                    data = resp.json()
                    products = data.get('data', {}).get('products', [])
                    total = data.get('data', {}).get('total', 0)
                    return {'page': page_num, 'products': products, 'total': total, 'status': 200}
                except Exception:
                    return {'page': page_num, 'products': [], 'total': 0, 'status': 'JSON_ERR'}
            
            elif resp.status_code == 429:
                logger.warning(f"‚ö†Ô∏è Page {page_num}: 429 Blocked (Try Proxy)")
            
            return {'page': page_num, 'products': [], 'total': 0, 'status': resp.status_code}
            
        except Exception as e:
            logger.error(f"‚ùå Page {page_num} Error: {e}")
            return {'page': page_num, 'products': [], 'total': 0, 'status': 'CONN_ERR'}

wb_search_service = WBSearchService()