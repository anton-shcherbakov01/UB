import logging
import asyncio
import json
from typing import List

from celery_app import celery_app
from parser_service import parser_service, GEO_ZONES
from analysis_service import analysis_service
from services.queue_service import queue_service
from .utils import save_history_sync, save_seo_position_sync

logger = logging.getLogger("Tasks-SEO")

@celery_app.task(bind=True, name="analyze_reviews_task")
def analyze_reviews_task(self, sku: int, limit: int = 50, user_id: int = None):
    """
    ÐÐ½Ð°Ð»Ð¸Ð· Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð² Ñ‚Ð¾Ð²Ð°Ñ€Ð° Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ AI.
    ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð²ÑÐµ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ðµ Ð¾ÑˆÐ¸Ð±ÐºÐ¸, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð¿Ð°Ð´Ð°Ñ‚ÑŒ.
    """
    task_id = self.request.id
    logger.info(f"ðŸš€ [TASK START] analyze_reviews_task | task_id={task_id} | sku={sku} | limit={limit} | user_id={user_id}")
    
    try:
        self.update_state(state='PROGRESS', meta={'status': 'ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡ÐºÐ¸ Ð¸ Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð²...'})
        logger.info(f"ðŸ“Š [PROGRESS] Parsing product info for SKU {sku} (task_id={task_id})")
        
        # Wrap parsing in try-except to catch any exceptions
        product_info = None
        try:
            product_info = parser_service.get_full_product_info(sku, limit)
        except Exception as parse_error:
            logger.error(f"Product parsing exception for SKU {sku}: {parse_error}", exc_info=True)
            # Remove from queue on error
            try:
                queue_service.remove_task_from_queue(self.request.id)
            except:
                pass
            return {"status": "error", "error": f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° Ñ‚Ð¾Ð²Ð°Ñ€Ð°: {str(parse_error)}"}
        
        # Check if product_info is None or empty
        if product_info is None:
            logger.error(f"Product info is None for SKU {sku}")
            try:
                queue_service.remove_task_from_queue(self.request.id)
            except:
                pass
            return {"status": "error", "error": "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¾ Ñ‚Ð¾Ð²Ð°Ñ€Ðµ"}
        
        # Check if product_info has error status
        if isinstance(product_info, dict) and product_info.get("status") == "error":
            error_msg = product_info.get("message", "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° Ñ‚Ð¾Ð²Ð°Ñ€Ð°")
            logger.error(f"Product parsing error for SKU {sku}: {error_msg}")
            try:
                queue_service.remove_task_from_queue(self.request.id)
            except:
                pass
            return {"status": "error", "error": error_msg}
        
        # Validate product_info structure
        if not isinstance(product_info, dict):
            logger.error(f"Product info is not a dict for SKU {sku}, got {type(product_info)}")
            try:
                queue_service.remove_task_from_queue(self.request.id)
            except:
                pass
            return {"status": "error", "error": "ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð°Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¾ Ñ‚Ð¾Ð²Ð°Ñ€Ðµ"}
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÐµÑ€Ð¸Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼Ð¾ÑÑ‚Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿ÐµÑ€ÐµÐ´ Ð´Ð°Ð»ÑŒÐ½ÐµÐ¹ÑˆÐµÐ¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¾Ð¹
        try:
            json.dumps(product_info)  # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÐµÑ€Ð¸Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼Ð¾ÑÑ‚Ð¸
        except (TypeError, ValueError) as ser_error:
            logger.error(f"Product info not serializable for SKU {sku}: {ser_error}")
            try:
                queue_service.remove_task_from_queue(self.request.id)
            except:
                pass
            return {"status": "error", "error": "Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð½Ðµ Ð¼Ð¾Ð³ÑƒÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ñ‹ (Ð¾ÑˆÐ¸Ð±ÐºÐ° ÑÐµÑ€Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸)"}
        
        self.update_state(state='PROGRESS', meta={'status': 'ABSA ÐÐ½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ° (DeepSeek-V3)...'})
        
        # Safely extract reviews
        reviews = product_info.get('reviews', [])
        if not isinstance(reviews, list):
            logger.warning(f"Reviews is not a list for SKU {sku}, got {type(reviews)}")
            reviews = []
        
        # Safely extract product name
        product_name = product_info.get('name') or product_info.get('product_name') or f"Ð¢Ð¾Ð²Ð°Ñ€ {sku}"
        if not isinstance(product_name, str):
            product_name = str(product_name) if product_name else f"Ð¢Ð¾Ð²Ð°Ñ€ {sku}"
        
        # AI Analysis with error handling
        try:
            ai_result = analysis_service.analyze_reviews_with_ai(reviews, product_name)
            if not isinstance(ai_result, dict):
                logger.warning(f"AI result is not a dict for SKU {sku}, got {type(ai_result)}")
                ai_result = {
                    "_error": "ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð¾Ñ‚Ð²ÐµÑ‚Ð° AI",
                    "aspects": [],
                    "audience_stats": {"rational_percent": 0, "emotional_percent": 0, "skeptic_percent": 0},
                    "global_summary": "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ðµ Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð²",
                    "flaws": ["ÐžÑˆÐ¸Ð±ÐºÐ° Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð° Ð¾Ñ‚Ð²ÐµÑ‚Ð°"],
                    "strategy": ["ÐŸÐ¾Ð²Ñ‚Ð¾Ñ€Ð¸Ñ‚Ðµ Ð¿Ð¾Ð¿Ñ‹Ñ‚ÐºÑƒ"]
                }
        except Exception as ai_error:
            logger.error(f"AI analysis exception for SKU {sku}: {ai_error}", exc_info=True)
            ai_result = {
                "_error": f"ÐžÑˆÐ¸Ð±ÐºÐ° AI Ð°Ð½Ð°Ð»Ð¸Ð·Ð°: {str(ai_error)}",
                "aspects": [],
                "audience_stats": {"rational_percent": 0, "emotional_percent": 0, "skeptic_percent": 0},
                "global_summary": "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ðµ Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð²",
                "flaws": ["Ð¡ÐµÑ€Ð²Ð¸Ñ AI Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½"],
                "strategy": ["ÐŸÐ¾Ð²Ñ‚Ð¾Ñ€Ð¸Ñ‚Ðµ Ð¿Ð¾Ð¿Ñ‹Ñ‚ÐºÑƒ Ð¿Ð¾Ð·Ð¶Ðµ"]
            }

        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð² AI Ð¾Ñ‚Ð²ÐµÑ‚Ðµ
        if ai_result.get("_error"):
            logger.error(f"AI analysis error for SKU {sku}: {ai_result['_error']}")
            # ÐÐµ Ð¿Ñ€ÐµÑ€Ñ‹Ð²Ð°ÐµÐ¼ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ, Ð½Ð¾ Ð¿Ð¾Ð¼ÐµÑ‚Ð¸Ð¼ Ð² Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ðµ

        # Build final result safely with explicit type conversion
        try:
            final_result = {
                "status": "success",
                "sku": int(sku),
                "product_name": str(product_name),
                "image": str(product_info.get('image') or product_info.get('image_url') or ""),
                "rating": float(product_info.get('rating', 0.0)),
                "reviews_count": int(len(reviews)),
                "ai_analysis": ai_result  # ai_result ÑƒÐ¶Ðµ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ ÑÐ»Ð¾Ð²Ð°Ñ€ÐµÐ¼
            }
            
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÐµÑ€Ð¸Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼Ð¾ÑÑ‚Ð¸ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°
            json.dumps(final_result)
        except (TypeError, ValueError) as ser_error:
            logger.error(f"Final result not serializable for SKU {sku}: {ser_error}", exc_info=True)
            try:
                queue_service.remove_task_from_queue(self.request.id)
            except:
                pass
            return {"status": "error", "error": f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐµÑ€Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°: {str(ser_error)}"}
        except Exception as result_error:
            logger.error(f"Error building final result for SKU {sku}: {result_error}", exc_info=True)
            try:
                queue_service.remove_task_from_queue(self.request.id)
            except:
                pass
            return {"status": "error", "error": f"ÐžÑˆÐ¸Ð±ÐºÐ° Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°: {str(result_error)}"}

        # Save history with error handling
        if user_id:
            try:
                title = f"ABSA: {product_name[:30]} ({len(reviews)} Ð¾Ñ‚Ð·.)"
                save_history_sync(user_id, sku, 'ai', title, final_result)
            except Exception as save_error:
                logger.error(f"Failed to save history for SKU {sku}, user {user_id}: {save_error}", exc_info=True)
                # ÐÐµ Ð¿Ñ€ÐµÑ€Ñ‹Ð²Ð°ÐµÐ¼ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ, Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð²ÑÐµ Ñ€Ð°Ð²Ð½Ð¾ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼
        
        # Remove task from queue after successful completion
        try:
            queue_service.remove_task_from_queue(self.request.id)
        except Exception as queue_e:
            logger.warning(f"Error removing task from queue: {queue_e}")

        logger.info(f"âœ… [TASK SUCCESS] analyze_reviews_task | task_id={task_id} | sku={sku} | reviews_count={len(reviews)} | user_id={user_id}")
        
        # Ð£Ð±ÐµÐ¶Ð´Ð°ÐµÐ¼ÑÑ, Ñ‡Ñ‚Ð¾ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ ÑÐµÑ€Ð¸Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼ Ð² JSON
        try:
            json_result = json.dumps(final_result)
            logger.debug(f"Result serialization check passed for task_id={task_id} (size={len(json_result)} bytes)")
        except (TypeError, ValueError) as ser_err:
            logger.error(f"âŒ [SERIALIZATION ERROR] task_id={task_id}: {ser_err}", exc_info=True)
            return {"status": "error", "error": f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐµÑ€Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°: {str(ser_err)}"}
        
        return final_result
    except Exception as e:
        logger.error(f"âŒ [TASK ERROR] analyze_reviews_task | task_id={task_id} | sku={sku} | error={str(e)}", exc_info=True)
        # Try to remove from queue on final error
        try:
            queue_service.remove_task_from_queue(self.request.id)
        except:
            pass
        return {"status": "error", "error": str(e)}

@celery_app.task(bind=True, name="generate_seo_task")
def generate_seo_task(self, keywords: list, tone: str, sku: int = 0, user_id: int = None, title_len: int = 100, desc_len: int = 1000):
    try:
        self.update_state(state='PROGRESS', meta={'status': 'Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ GEO ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°...'})
        
        content = analysis_service.generate_product_content(keywords, tone, title_len, desc_len)
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð² AI Ð¾Ñ‚Ð²ÐµÑ‚Ðµ
        if content.get("_error"):
            logger.error(f"AI generation error: {content['_error']}")
            # ÐÐµ Ð¿Ñ€ÐµÑ€Ñ‹Ð²Ð°ÐµÐ¼ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ, Ð½Ð¾ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾Ð± Ð¾ÑˆÐ¸Ð±ÐºÐµ Ð±ÑƒÐ´ÐµÑ‚ Ð² Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ðµ
        
        final_result = {
            "status": "success",
            "sku": sku,
            "keywords": keywords,
            "tone": tone,
            "generated_content": content 
        }
        
        if user_id and sku > 0:
            title = f"GEO: {content.get('title', 'Ð‘ÐµÐ· Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ°')[:20]}..."
            save_history_sync(user_id, sku, 'seo', title, final_result)
            
        return final_result
    except Exception as e:
        logger.error(f"Generate SEO task error: {e}", exc_info=True)
        return {"status": "error", "error": str(e)}

@celery_app.task(bind=True, name="cluster_keywords_task")
def cluster_keywords_task(self, keywords: List[str], user_id: int = None, sku: int = 0):
    self.update_state(state='PROGRESS', meta={'status': 'Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° BERT Ð¼Ð¾Ð´ÐµÐ»Ð¸...'})
    
    result = analysis_service.cluster_keywords(keywords)
    
    if user_id and sku > 0:
        title = f"Clusters: {len(keywords)} keys ({result.get('n_clusters', 0)} groups)"
        save_history_sync(user_id, sku, 'clusters', title, result)
        
    return result

@celery_app.task(bind=True, name="check_seo_position_task")
def check_seo_position_task(self, sku: int, keyword: str, user_id: int, regions: List[str] = None):
    self.update_state(state='PROGRESS', meta={'status': 'Geo Tracking...'})
    if not regions: regions = ["moscow"]

    async def check_all_regions():
        tasks = []
        for reg_name in regions:
            dest_id = GEO_ZONES.get(reg_name.lower(), GEO_ZONES["moscow"])
            tasks.append(parser_service.get_search_position_v2(keyword, sku, dest=dest_id))
        return await asyncio.gather(*tasks)

    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        results = loop.run_until_complete(check_all_regions())
        loop.close()
        
        main_result = results[0]
        db_position = main_result["organic_pos"]
        save_seo_position_sync(user_id, sku, keyword, db_position)
        
        detailed_report = {}
        for reg, res in zip(regions, results): detailed_report[reg] = res

        return {"status": "success", "sku": sku, "keyword": keyword, "main_position": db_position, "geo_details": detailed_report}

    except Exception as e:
        logger.error(f"SEO Check Task Error: {e}")
        return {"status": "error", "message": str(e)}